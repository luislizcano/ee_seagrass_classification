{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Automated Seagrass Classification Using Earth Engine Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script classify dense seagrass beds in satellite images (from Sentinel and Landsat sensors) using machine learning (Support Vector Machine). The outputs can be exported to EE Assets. All the training and validation matrices and accuracies can be saved as an Excel file in your working directory.<br/>\n",
    "**NOTE:** The classifications will use only the aerosol (if available), blue, green, red and Blue/Green (from Depth Invariant Index) bands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script by: Luis Lizcano-Sandoval<br/>\n",
    "College of Marine Sciences, University of South Florida<br/>\n",
    "luislizcanos@usf.edu<br/>\n",
    "Updated: 09/03/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**Workflow:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import required images, collections, data, etc.\n",
    "2. Mask clouds, land, and deep areas >20m\n",
    "3. Apply Depth-Invariant Index (band-ratios)\n",
    "4. Sample bands: B1, B2, B3, B4, B/G\n",
    "5. Train models and classify (SVM)\n",
    "6. Get confusion matrices and accuracies\n",
    "7. Export output to EE Assets (.tiff)\n",
    "8. Save matrices in local computer (.xlxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()),'bin'))\n",
    "import datetime\n",
    "from functions import CloudScore6S,landMaskFunction,DII\n",
    "from IPython.display import display, Image\n",
    "\n",
    "ee.Initialize()\n",
    "print('EE API version: ',ee.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Settings and Metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the type of satellite\n",
    "satellite = 'Sentinel2'\n",
    "# satellite = 'Landsat8'\n",
    "# satellite = 'Landsat7'\n",
    "# satellite = 'Landsat5'\n",
    "\n",
    "## Some settings:\n",
    "#imageID = 'LT05_016041_19890205' ## Landsat-5 Image ID\n",
    "# imageID = 'LC08_015043_20200204' ## Landsat-8 Image ID\n",
    "imageID = '20191207T160509_20191207T160505_T17RNH' ## Sentinel-2 Image ID\n",
    "asset = 'users/lizcanosandoval/Seagrass/' ## Partial name of the EE asse to save the final output.\n",
    "exportFolder = 'Florida_Seagrass' ## Name of EE folder to save the final output.\n",
    "smoothStr = '_raw_' # Smooth classified pixels or not? options: '_smooth_' or '_raw_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**1. Import files:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import BOA images and extract metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load BOA image collection:\n",
    "if 'Sentinel' in satellite:\n",
    "    image = ee.Image(\"COPERNICUS/S2_SR/\"+imageID)\n",
    "elif 'Landsat8' == satellite:\n",
    "    image = ee.Image(\"LANDSAT/LC08/C01/T1_SR/\"+imageID)\n",
    "elif 'Landsat7' == satellite:\n",
    "    image = ee.Image(\"LANDSAT/LE07/C01/T1_SR/\"+imageID)\n",
    "elif 'Landsat5' == satellite:\n",
    "    image = ee.Image(\"LANDSAT/LT05/C01/T1_SR/\"+imageID)\n",
    "\n",
    "## Get image metadata:\n",
    "if 'Sentinel' in satellite:\n",
    "    imageTarget = image.divide(10000).set(image.toDictionary(image.propertyNames()))\n",
    "    imageSat = imageTarget.get('SPACECRAFT_NAME').getInfo() #Image satellite\n",
    "    imageTile = imageTarget.get('MGRS_TILE').getInfo() #Image tile id\n",
    "    ee_date = imageTarget.get('GENERATION_TIME').getInfo()\n",
    "    imageDate = str(datetime.datetime.utcfromtimestamp(ee_date/1000.0)) #Image date\n",
    "    imageGeometry = imageTarget.geometry() #Tile geometry.\n",
    "elif 'Landsat8' == satellite:\n",
    "    imageTarget = image.divide(10000).set(image.toDictionary(image.propertyNames()))\n",
    "    #imageSat = imageTarget.get('SATELLITE').getInfo() #Image satellite\n",
    "    imageSat = satellite\n",
    "    imageTile = str(imageTarget.get('WRS_PATH').getInfo())+str(imageTarget.get('WRS_ROW').getInfo()) #Image tile id\n",
    "    imageDate = imageTarget.get('SENSING_TIME').getInfo()\n",
    "    imageGeometry = imageTarget.geometry() #Tile geometry.\n",
    "        \n",
    "if 'Sentinel' in imageSat:\n",
    "    imageScale = 10 # Sentinel resolution\n",
    "else:\n",
    "    imageScale = 30 # Landsat resolution\n",
    "\n",
    "print('Satellite: ',imageSat)\n",
    "print('Tile: ',imageTile)\n",
    "print('Date: ',imageDate)\n",
    "print(imageDate[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define RGB bands:\n",
    "if 'Sentinel' or 'Landsat8' in imageSat:\n",
    "    rgb = ['B4','B3','B2']\n",
    "else:\n",
    "    rgb = ['B3','B2','B1'] ##Landsat7/5\n",
    "\n",
    "## Setting for displaying images:\n",
    "def displaySettings(image, channels):\n",
    "    img = Image(url=image.select(channels).getThumbUrl({\n",
    "        'dimensions': '500x500',\n",
    "        'min':0,\n",
    "        'max':0.2,\n",
    "        'gamma':1.8\n",
    "        }))\n",
    "    return display(img)\n",
    "\n",
    "## Display image:\n",
    "originalImage = displaySettings(imageTarget, rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Load other collections and data:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground-Points [For Training and Validation]\n",
    "groundPoints = ee.FeatureCollection(\"users/lizcanosandoval/public/Points_example\")\n",
    "\n",
    "# Sandy areas [Polygons] - For Water Column Correction [DII]\n",
    "sand_areas = ee.FeatureCollection(\"users/lizcanosandoval/public/Sand_example\")\n",
    "\n",
    "## Florida Bathymetry [NOAA-90m res]\n",
    "bathymetry = ee.Image(\"users/lizcanosandoval/Bathymetry_FL\")\n",
    "\n",
    "## Land [from GADM-HiRes 3.6]\n",
    "land = ee.FeatureCollection(\"users/lizcanosandoval/gadm36_FL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Prepare bathymetry data:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mask depth ranges [Mask depth range from -20 to 2 meters]\n",
    "bathy_masked = ee.Image(bathymetry).updateMask(bathymetry.lt(2).And(bathymetry.gt(-25)))\n",
    "\n",
    "## Clip bathymetry to the tile geometry/bounds:\n",
    "bathyBand = bathy_masked.clip(imageGeometry)\n",
    "\n",
    "## Vectorize (to FeatureCollection of polygons) the bathymetry collection,\n",
    "## which is a raster image.\n",
    "bathyVector = bathyBand.toByte().reduceToVectors(**{\n",
    "  'reducer': ee.Reducer.countEvery(),\n",
    "  'crs': 'EPSG:4326',\n",
    "  'geometry': None,\n",
    "  'eightConnected': False,\n",
    "  'labelProperty': 'bathymetry',\n",
    "  'scale': 1000,\n",
    "  'geometryType': 'polygon',\n",
    "  'maxPixels': 1e9\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**2. Apply masks to image:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cloud mask:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Recommended Threshold values for\n",
    "## *Sentinel: 2-10\n",
    "## *Landsat: 5-10\n",
    "## The lower threshold the more sensitive to clouds and land/urban areas.\n",
    "if 'Sentinel' in imageSat:\n",
    "    threshold = 5\n",
    "else:\n",
    "    threshold = 5\n",
    "\n",
    "## Apply cloud mask\n",
    "cloudMask = CloudScore6S(imageSat, imageTarget, threshold)\n",
    "\n",
    "## Display image:\n",
    "cloudImage = displaySettings(cloudMask, rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Land mask:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Apply land mask\n",
    "landMask = landMaskFunction(cloudMask, land)\n",
    "\n",
    "## Display image:\n",
    "landImage = displaySettings(landMask, rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bathymetry mask:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Apply bathymetry mask\n",
    "bathyMask = landMask.clip(bathyVector) ##Using the NOAA dataset: bathyVector\n",
    "\n",
    "## Display image:\n",
    "bathyImage = displaySettings(bathyMask, rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turbidity mask:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Turbidity masking is based on the red band reflectances, based on own observations (in South Florida). \n",
    "## Values higher than 0.02-0.03 indicates turbid waters, but sometimes may indicate shallow \"seagrass banks\".\n",
    "## So the below algorithm try to separate shallow seagrasses from turbidity.\n",
    "\n",
    "## Set parameter values\n",
    "if 'Sentinel' in imageSat:\n",
    "    red_band = 'B4' #Red seems work better in this case than B5.\n",
    "    red_thr_inf = 0.025\n",
    "    red_thr_sup = 0.2\n",
    "    green_band = 'B3'\n",
    "    green_thr = 0.15\n",
    "    blue_band = 'B2'\n",
    "    blue_thr = 0.11\n",
    "elif 'Landsat8' in imageSat:\n",
    "    red_band = 'B4'\n",
    "    red_thr_inf = 0.025\n",
    "    red_thr_sup = 0.2\n",
    "    green_band = 'B3'\n",
    "    green_thr = 0.15\n",
    "    blue_band = 'B2'\n",
    "    blue_thr = 0.11\n",
    "else:\n",
    "    red_band = 'B3'\n",
    "    red_thr_inf = 0.03 #Landsat5/7 are less sensitive\n",
    "    red_thr_sup = 0.2\n",
    "    green_band = 'B2'\n",
    "    green_thr = 0.15\n",
    "    blue_band = 'B1'\n",
    "    blue_thr = 0.11\n",
    "\n",
    "## Select the red band\n",
    "selectRedBand = bathyMask.select(red_band)\n",
    "\n",
    "## Identify turbid areas first (pixel values higher than the threshold)\n",
    "turbidMask = selectRedBand.gt(red_thr_inf)\n",
    "\n",
    "## Apply thresholds on red, green and blue bands\n",
    "maskRed = selectRedBand.gt(red_thr_inf).And(selectRedBand.lt(red_thr_sup))\n",
    "imageMaskRed = bathyMask.mask(maskRed)\n",
    "maskGreen = imageMaskRed.select(green_band).lt(green_thr)\n",
    "imageMaskGreen = imageMaskRed.mask(maskGreen)\n",
    "maskBlue = imageMaskGreen.select(blue_band).lt(blue_thr) ##Shallow seagrass\n",
    "\n",
    "## Final mask (excluding seagrass/including turbid water)\n",
    "turbidImage = bathyMask.mask(turbidMask) ## Turbidity\n",
    "seagrassImage = bathyMask.mask(maskBlue).mask().Not() ## Shallow seagrass (inverse mask)\n",
    "excludeSeagrass = turbidImage.updateMask(seagrassImage) ## Turbidity minus shallow seagrass\n",
    "finalMaskImage = bathyMask.mask(excludeSeagrass)\n",
    "finalMask = finalMaskImage.mask().Not()\n",
    "\n",
    "## Final Image\n",
    "finalImage = bathyMask.updateMask(finalMask)\n",
    "\n",
    "## Display image:\n",
    "#cleanImage = displaySettings(finalImage, rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**3. Water column correction:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter sand polygons by tile/area:\n",
    "sand = ee.FeatureCollection(sand_areas).filterBounds(imageGeometry)\n",
    "print('Number of sand polygons: ',sand.size().getInfo())\n",
    "\n",
    "## Run the Depth-Invariant Index Function\n",
    "imageDII = DII(finalImage, imageScale, sand)\n",
    "#print(imageDII.getInfo())\n",
    "\n",
    "## Display one of the bands ['B1B2', 'B1B3', 'B2B3']\n",
    "imgDII = Image(url=imageDII.select('B2B3').getThumbUrl({\n",
    "    'dimensions': '500x500',\n",
    "    'min':-3,\n",
    "    'max':1,\n",
    "    'gamma':1.5\n",
    "    }))\n",
    "#display(imgDII)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**4. Sampling Data:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes in the Ground-Truth dataset are:\n",
    "* 0: Softbottom\n",
    "* 1: Hardbottom\n",
    "* 2: Seagrass\n",
    "* 3: Sparse seagrass //if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter ground points by tile geometry and display classes\n",
    "filterPoints = ee.FeatureCollection(groundPoints).filterBounds(imageGeometry)\n",
    "print('Classes: ', filterPoints.aggregate_array('class').distinct().getInfo())\n",
    "print('Ground Points per Class:', filterPoints.aggregate_histogram('class').getInfo())\n",
    "\n",
    "## Number of points:\n",
    "totalPoints = filterPoints.size()\n",
    "print('Total points:', totalPoints.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the bands to sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select bands to sample. The B/G band is B2B3 in Sentinel-2 and Landsat-8, and B1B2 for Landsat-7/5\n",
    "if 'Sentinel' in imageSat or 'Landsat8' in imageSat:\n",
    "    bandsClass = ['B1','B2', 'B3', 'B4','B2B3']\n",
    "    bg = ['B2B3']\n",
    "else:\n",
    "    bandsClass = ['B1','B2', 'B3', 'B1B2']\n",
    "    bg = ['B1B2']\n",
    "    \n",
    "## Add bands of interest to sample training points:\n",
    "imageClassify = finalImage.addBands(imageDII.select(bg)).select(bandsClass)\n",
    "print('Bands to sample:',imageClassify.bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPTIONAL:** Make training within any specified area (e.g. polygon, shallow areas, or any area of interest). In this case, the bathymetry mask may be no needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Polygon of known seagrass habitats + 5 km \n",
    "# seagrass_buffer = ee.FeatureCollection(\"users/lizcanosandoval/Seagrass_Habitat_Florida_buff5k\")\n",
    "# imageClassify = imageClassify.clip(seagrass_buffer) #For polygons\n",
    "# cleanImage = displaySettings(imageClassify, rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**APPLY SMOOTHER IF SET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply smoother if set:\n",
    "if 'smooth' in smoothStr:\n",
    "    ## Define a boxcar or low-pass kernel (Used if want to smooth the image)\n",
    "    smooth = ee.Kernel.euclidean(**{\n",
    "        'radius': 1, \n",
    "        'units': 'pixels', \n",
    "        'normalize': True\n",
    "    })\n",
    "    imageClassify = imageClassify.convolve(smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample multi-spectral data using all ground points.\n",
    "samplingData = imageClassify.sampleRegions(**{\n",
    "    'collection': filterPoints,\n",
    "    'properties': ['class'],\n",
    "    'scale': imageScale})\n",
    "\n",
    "## Add random numbers to each feature (from 0 to 1).\n",
    "randomData = samplingData.randomColumn(\"random\",0)\n",
    "\n",
    "## Split ground data in training (~70%) and validation (~30%) points\n",
    "trainingData = randomData.filter(ee.Filter.lt(\"random\",0.7))\n",
    "validationData = randomData.filter(ee.Filter.gte(\"random\", 0.7))\n",
    "\n",
    "print('Training Points per Class:', trainingData.aggregate_histogram('class').getInfo())\n",
    "print('Validation Points per Class:', validationData.aggregate_histogram('class').getInfo())\n",
    "print('Training Samples (70%):',trainingData.size().getInfo())\n",
    "print('Validation Samples (30%):',validationData.size().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**5. Train models and Classify:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train SVM classifier\n",
    "SVM = ee.Classifier.libsvm(**{\n",
    "   'kernelType': 'RBF',\n",
    "   'gamma': 100,\n",
    "   'cost': 100\n",
    "})\n",
    "trainSVM = SVM.train(**{\n",
    "   'features': trainingData,\n",
    "   'classProperty': 'class',\n",
    "   'inputProperties': bandsClass\n",
    "})\n",
    "\n",
    "#### Classify the image using the trained classifier\n",
    "classifiedSVM = imageClassify.classify(trainSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display classified images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a palette for the distinct classes\n",
    "classPalette = ['#3090C7','#CD7F32','#004E00']#,'#78F878']\n",
    "\n",
    "imgSVM = Image(url=classifiedSVM.getThumbUrl({\n",
    "    'dimensions': '500x500',\n",
    "    'min':0,\n",
    "    'max':2,\n",
    "    'palette': classPalette\n",
    "    }))\n",
    "\n",
    "display(imgSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**6. Get accuracy matrices:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a confusion matrix representing resubstitution accuracy.\n",
    "## {Resubstitution error is the error of a model on the training data.}\n",
    "## Axis 0 (first level) of the matrix correspond to the input classes (columns), \n",
    "## and axis 1 (second level) to the output classes (rows).\n",
    "matrixTrainingSVM = trainSVM.confusionMatrix()\n",
    "\n",
    "#print('SVM Training Confusion Matrix: ', matrixTrainingSVM.getInfo())\n",
    "\n",
    "print('SVM Training overall accuracy: ', round((matrixTrainingSVM.accuracy().getInfo()), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate accuracy using validation data\n",
    "## Classify the image using the trained classifier\n",
    "validationSVM = validationData.classify(trainSVM)\n",
    "\n",
    "## Get a confusion matrix representing expected accuracy (Using validation points - 30%), where:\n",
    "#  0: Softbottom\n",
    "#  1: Hardbottom\n",
    "#  2: Dense Seagrass\n",
    "#  3: Spare Seagrass\n",
    "\n",
    "## Axis 0 (the rows) of the matrix correspond to the actual values, \n",
    "## and Axis 1 (the columns) to the predicted values.\n",
    "errorMx = {'actual': 'class', 'predicted': 'classification'}\n",
    "errorMatrixSVM = validationSVM.errorMatrix(**errorMx)\n",
    "\n",
    "#print('SVM Validation Error Matrix: ', errorMatrixSVM.getInfo())\n",
    "\n",
    "print('SVM validation overall accuracy: ', round((errorMatrixSVM.accuracy().getInfo()), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User and Producer accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estimate user and producer accuracies\n",
    "producerAccuracySVM = errorMatrixSVM.producersAccuracy()\n",
    "\n",
    "userAccuracySVM = errorMatrixSVM.consumersAccuracy()\n",
    "\n",
    "#print('Producer Accuracy SVM: ',producerAccuracySVM.getInfo())\n",
    "#print('User Accuracy SVM: ',userAccuracySVM.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print accuracies as Pandas format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a pandas dataframe with producer and user accuracies:\n",
    "rowIndex = {0:'Sb', 1:'Hb', 2:'Dn', 3:'Sp'}\n",
    "dfPA_SVM = pd.DataFrame(producerAccuracySVM.getInfo(), columns=['Producer'])\n",
    "dfUA_SVM = pd.DataFrame(userAccuracySVM.getInfo()).transpose()\n",
    "\n",
    "PU_SVM = pd.concat([dfPA_SVM, dfUA_SVM.rename(columns={0:'User'})], axis=1).rename(index=rowIndex)\n",
    "\n",
    "print('\\n SVM: \\n', PU_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kappa coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Kappa Coefficient is generated from a statistical test to evaluate the accuracy \n",
    "# of a classification. Kappa essentially evaluate how well the classification performed \n",
    "# as compared to just randomly assigning values, i.e. did the classification do better \n",
    "# than random. The Kappa Coefficient can range from -1 t0 1. A value of 0 indicated that \n",
    "# the classification is no better than a random classification. A negative number \n",
    "# indicates the classification is significantly worse than random. A value close to 1 \n",
    "# indicates that the classification is significantly better than random.\n",
    "\n",
    "kappaSVM = errorMatrixSVM.kappa()\n",
    "\n",
    "print('Kappa SVM: ', round((kappaSVM.getInfo()), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**7. Export Classified Images:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the scale properly\n",
    "scale = []\n",
    "sat = []\n",
    "method = 'SVM'\n",
    "print('Wait for submission')\n",
    " \n",
    "# Rename satellite\n",
    "if 'Sentinel' in imageSat:\n",
    "    sat = 'Sentinel'\n",
    "else:\n",
    "    sat = 'Landsat'\n",
    "\n",
    "## Select classified image\n",
    "imageFinal = ee.Image(classifiedSVM)\n",
    "\n",
    "# set some properties for export\n",
    "output = imageFinal.set({'satellite': imageSat,\n",
    "               'tile_id': imageTile,\n",
    "               'file_id': imageID,                                               \n",
    "               'date': imageDate,\n",
    "               'year': imageDate[0:4],\n",
    "               'classifier': method,\n",
    "               'generator': 'Lizcano-Sandoval',\n",
    "                    })\n",
    "\n",
    "# define YOUR assetID. (This do not create folders, you need to create them manually)\n",
    "assetID = asset + sat + '/' + exportFolder + '/' ##This goes to an ImageCollection folder\n",
    "fileName = imageID+smoothStr+ method\n",
    "path = assetID + fileName\n",
    "\n",
    "## Batch Export to Assets\n",
    "ee.batch.Export.image.toAsset(\\\n",
    "    image = ee.Image(output),                                                    \n",
    "    description = method +smoothStr+ imageID,\n",
    "    assetId = path,\n",
    "    region = imageGeometry.buffer(10),                                      \n",
    "    maxPixels = 1e13,\n",
    "    scale = imageScale).start()\n",
    "print('Classified Image '+str(i+1)+': '+imageID +smoothStr+ method+' submitted...')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**8. Save Matrices to Working Directory:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract values from each matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_trainingMatrix = matrixTrainingSVM.array().getInfo()\n",
    "SVM_trainingAccuracy = matrixTrainingSVM.accuracy().getInfo()\n",
    "SVM_errorMatrix = errorMatrixSVM.array().getInfo()\n",
    "SVM_errorAccuracy = errorMatrixSVM.accuracy().getInfo()\n",
    "SVM_producerAccuracy = producerAccuracySVM.getInfo()\n",
    "SVM_userAccuracy = userAccuracySVM.getInfo()\n",
    "SVM_kappa = kappaSVM.getInfo()\n",
    "\n",
    "print('These matrices needs to be reformatted, e.g.: ', SVM_trainingMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert matrices to pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Matrices\n",
    "TM_SVM = pd.DataFrame(SVM_trainingMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "TM_concat = pd.concat([TM_SVM], keys=['SVM'])\n",
    "\n",
    "#Training Accuracies\n",
    "TA_SVM = pd.Series(SVM_trainingAccuracy)\n",
    "TA_concat = pd.DataFrame(pd.concat([TA_SVM],ignore_index=True), columns=(['Tr_Accuracy']))\\\n",
    "                .rename({0:'SVM'})\n",
    "\n",
    "#Validation-Error Matrices\n",
    "VM_SVM = pd.DataFrame(SVM_errorMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "VM_concat = pd.concat([VM_SVM], keys=['SVM'])\n",
    "\n",
    "#Validation Accuracies\n",
    "VA_SVM = pd.Series(SVM_errorAccuracy)\n",
    "VA_concat = pd.DataFrame(pd.concat([VA_SVM],ignore_index=True), columns=(['Va_Accuracy']))\\\n",
    "                .rename({0:'SVM'})\n",
    "\n",
    "#Producer-User Accuracies\n",
    "PU_concat = pd.concat([PU_SVM], keys=['SVM'])\n",
    "\n",
    "#Kappa coefficients\n",
    "Kp_SVM = pd.Series(SVM_kappa)\n",
    "Kp_concat = pd.DataFrame(pd.concat([Kp_SVM],ignore_index=True), columns=(['Kappa']))\\\n",
    "                .rename({0:'SVM'})\n",
    "\n",
    "Kp_concat.style.set_caption('Kappa coefficients')\n",
    "#print(Kp_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the number of training and validation points per class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingInfo = trainingData.aggregate_histogram('class').getInfo()\n",
    "validationInfo = validationData.aggregate_histogram('class').getInfo()\n",
    "\n",
    "traSeries = pd.Series(trainingInfo)\n",
    "valSeries = pd.Series(validationInfo)\n",
    "\n",
    "Points_concat = pd.DataFrame(pd.concat([traSeries, valSeries],ignore_index=True,axis=1))\\\n",
    "                .rename(columns={0:'TraPoints',1:'ValPoints'}).rename({'0':'Sb','1':'Hb','2':'Dn'},axis='index')\n",
    "print(Points_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize each matrix in separate excel sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelName = 'Mrx'+ smoothStr + imageID +'.xlsx'\n",
    "excel = pd.ExcelWriter(excelName, engine='xlsxwriter')\n",
    "\n",
    "Points_concat.to_excel(excel, sheet_name='Points', index=True, startrow=0)\n",
    "TM_concat.to_excel(excel, sheet_name='TrMrx', index=True, startrow=0)\n",
    "TA_concat.to_excel(excel, sheet_name='TrAcc', index=True, startrow=0)\n",
    "VM_concat.to_excel(excel, sheet_name='VaMrx', index=True, startrow=0)\n",
    "VA_concat.to_excel(excel, sheet_name='VaAcc', index=True, startrow=0)\n",
    "PU_concat.to_excel(excel, sheet_name='PU-Mrx', index=True, startrow=0)\n",
    "Kp_concat.to_excel(excel, sheet_name='Kappa', index=True, startrow=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save matrices as .xlsx file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel.save()\n",
    "print('SAVED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
